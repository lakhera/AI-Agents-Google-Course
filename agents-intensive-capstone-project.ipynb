{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%bash\n# Create project folders in the Kaggle working directory\nmkdir -p /kaggle/working/agentsmentor/backend/agents\nmkdir -p /kaggle/working/agentsmentor/backend/mcp_tools\nmkdir -p /kaggle/working/agentsmentor/backend/tools\nmkdir -p /kaggle/working/agentsmentor/backend/memory\nmkdir -p /kaggle/working/agentsmentor/samples\nmkdir -p /kaggle/working/agentsmentor/artifacts/charts\nmkdir -p /kaggle/working/agentsmentor/artifacts/notebooks\n\n# Show the created structure\necho \"Created folders:\"\nls -R /kaggle/working/agentsmentor | sed -n '1,200p'\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-26T08:55:27.809Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile /kaggle/working/agentsmentor/backend/app.py\nimport streamlit as st\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\nimport uuid\n\nfrom agents.router_agent import route_query\nfrom agents.dataset_agent import analyze_dataset\nfrom agents.debug_agent import debug_code\nfrom agents.model_agent import suggest_model, generate_notebook\n\n# Streamlit App Settings\nst.set_page_config(page_title=\"AgentsMentor - Kaggle Concierge\", layout=\"wide\")\n\nBASE = Path(\"/kaggle/working/agentsmentor\")\nDATA_DIR = BASE / \"samples\"\nARTIFACTS_DIR = BASE / \"artifacts\"\nARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)\nDATA_DIR.mkdir(parents=True, exist_ok=True)\n\nst.title(\"ðŸ§  AgentsMentor â€“ Kaggle Problem-Solving Concierge (MVP)\")\n\n# Session initialization\nif \"dataset_id\" not in st.session_state:\n    st.session_state[\"dataset_id\"] = None\nif \"dataset_path\" not in st.session_state:\n    st.session_state[\"dataset_path\"] = None\n\nmenu = st.sidebar.selectbox(\n    \"Choose Action\",\n    [\"Upload Dataset\", \"Analyze Dataset\", \"Debug Code\", \"Generate Notebook\"]\n)\n\n# Upload Dataset\nif menu == \"Upload Dataset\":\n    st.header(\"ðŸ“¤ Upload a CSV Dataset\")\n    uploaded_file = st.file_uploader(\"Choose CSV file\", type=[\"csv\"])\n    if uploaded_file:\n        dataset_id = str(uuid.uuid4())\n        path = DATA_DIR / f\"{dataset_id}_{uploaded_file.name}\"\n        with open(path, \"wb\") as f:\n            f.write(uploaded_file.getvalue())\n        st.session_state[\"dataset_id\"] = dataset_id\n        st.session_state[\"dataset_path\"] = str(path)\n        st.success(f\"Dataset uploaded successfully! ID: {dataset_id}\")\n        st.write(\"Saved at:\", path)\n\n# Analyze Dataset\nif menu == \"Analyze Dataset\":\n    st.header(\"ðŸ“Š Dataset Insights\")\n    if not st.session_state[\"datase]()_\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-26T08:55:27.809Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# %%writefile /kaggle/working/agentsmentor/backend/agents/router_agent.py\n# backend/agents/router_agent.py\ndef route_query(text: str):\n    \"\"\"\n    Very small intent router for MVP.\n    Returns a dict: {\"intent\": \"dataset|debug|model|notebook|other\", \"summary\": \"one-line\"}\n    \"\"\"\n    if not text or not text.strip():\n        return {\"intent\": \"other\", \"summary\": \"empty\"}\n\n    t = text.lower().strip()\n\n    # debug-related keywords (code / error)\n    debug_keys = [\"error\", \"traceback\", \"exception\", \"stacktrace\", \"syntax error\", \"nameerror\", \"typeerror\", \"shape mismatch\", \"missing import\", \"bug\", \"fix this\"]\n    for k in debug_keys:\n        if k in t:\n            return {\"intent\": \"debug\", \"summary\": f\"debug: matched keyword '{k}'\"}\n\n    # dataset-related keywords\n    dataset_keys = [\"dataset\", \"column\", \"columns\", \"missing\", \"null\", \"dtype\", \"skew\", \"histogram\", \"eda\", \"explore\", \"feature\", \"target\"]\n    for k in dataset_keys:\n        if k in t:\n            return {\"intent\": \"dataset\", \"summary\": f\"dataset: matched keyword '{k}'\"}\n\n    # model / baseline / ml keywords\n    model_keys = [\"baseline\", \"model\", \"randomforest\", \"xgboost\", \"train\", \"validation\", \"score\", \"accuracy\", \"roc\", \"auc\"]\n    for k in model_keys:\n        if k in t:\n            return {\"intent\": \"model\", \"summary\": f\"model: matched keyword '{k}'\"}\n\n    # notebook generation / notebook\n    if \"notebook\" in t or \"generate\" in t and (\"notebook\" in t or \"script\" in t):\n        return {\"intent\": \"notebook\", \"summary\": \"generate notebook/script\"}\n\n    # fallback: use simple heuristics for questions\n    if t.endswith(\"?\"):\n        # prefer dataset if mentions column/row\n        if any(w in t for w in [\"column\", \"row\", \"how many\", \"what is\", \"which\"]):\n            return {\"intent\": \"dataset\", \"summary\": \"question - assume dataset\"}\n        return {\"intent\": \"other\", \"summary\": \"question fallback\"}\n    return {\"intent\": \"other\", \"summary\": \"fallback\"}\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-26T08:55:27.809Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile /kaggle/working/agentsmentor/backend/agents/dataset_agent.py\n# backend/agents/dataset_agent.py\nimport pandas as pd\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\n\ndef analyze_dataset(path: Path):\n    \"\"\"\n    Loads CSV at `path` and returns basic schema, missing counts, sample rows,\n    and generates a histogram for the first numeric column (if any).\n    Returns a dict:\n      {\n        \"schema\": [ {\"column\":..., \"dtype\":..., \"non_null_count\":...}, ...],\n        \"missing\": {col: missing_count, ...},\n        \"sample_rows\": [...],\n        \"chart\": \"artifacts/charts/xxx.png\" or None\n      }\n    \"\"\"\n    path = Path(path)\n    if not path.exists():\n        raise FileNotFoundError(f\"Dataset not found: {path}\")\n\n    df = pd.read_csv(path)\n\n    # Build schema\n    schema = []\n    for c in df.columns:\n        schema.append({\n            \"column\": c,\n            \"dtype\": str(df[c].dtype),\n            \"non_null_count\": int(df[c].count())\n        })\n\n    # Missing values\n    missing = {c: int(df[c].isna().sum()) for c in df.columns}\n\n    # Sample rows (small)\n    sample_rows = df.head(5).to_dict(orient=\"records\")\n\n    # Create chart artifact for first numeric column\n    numeric_cols = df.select_dtypes(include=\"number\").columns.tolist()\n    chart_path = None\n    if numeric_cols:\n        col = numeric_cols[0]\n        plt.figure(figsize=(6,3))\n        df[col].dropna().hist(bins=20)\n        plt.title(f\"Histogram: {col}\")\n        plt.tight_layout()\n        artifacts_dir = Path(\"/kaggle/working/agentsmentor/artifacts/charts\")\n        artifacts_dir.mkdir(parents=True, exist_ok=True)\n        fname = f\"{path.stem}_{col}_hist.png\"\n        out_path = artifacts_dir / fname\n        plt.savefig(out_path)\n        plt.close()\n        chart_path = str(out_path)\n\n    return {\n        \"schema\": schema,\n        \"missing\": missing,\n        \"sample_rows\": sample_rows,\n        \"chart\": chart_path\n    }\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-26T08:55:27.810Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile /kaggle/working/agentsmentor/backend/agents/debug_agent.py\n# backend/agents/debug_agent.py\nimport ast\nfrom typing import List, Dict\n\ndef _find_possible_missing_imports(code: str) -> List[Dict]:\n    \"\"\"\n    Very small heuristic checks for common sklearn/linalg/etc mentions\n    that may indicate missing imports. Returns list of suggestions.\n    \"\"\"\n    suggestions = []\n    lowered = code.lower()\n    # common sklearn classname checks\n    mapping = {\n        \"randomforestclassifier\": \"from sklearn.ensemble import RandomForestClassifier\",\n        \"xgboost\": \"import xgboost as xgb\",\n        \"pandas\": \"import pandas as pd\",\n        \"numpy\": \"import numpy as np\",\n        \"train_test_split\": \"from sklearn.model_selection import train_test_split\",\n    }\n    for key, imp in mapping.items():\n        if key in lowered and imp.split()[1] not in code:\n            suggestions.append({\"issue\": f\"Possible missing import related to '{key}'\", \"suggestion\": imp})\n    return suggestions\n\ndef debug_code(code: str):\n    \"\"\"\n    Static analysis for Python code (MVP).\n    Returns:\n      {\n        \"diagnostics\": [...],\n        \"fix\": \"suggested code snippet or notes\",\n        \"confidence\": float\n      }\n    \"\"\"\n    diagnostics = []\n    # Syntax check via ast\n    try:\n        ast.parse(code)\n    except SyntaxError as e:\n        diagnostics.append({\"type\": \"SyntaxError\", \"message\": str(e), \"lineno\": getattr(e, \"lineno\", None)})\n    except Exception as e:\n        diagnostics.append({\"type\": \"ParseError\", \"message\": str(e)})\n\n    # Heuristic missing imports\n    import_suggestions = _find_possible_missing_imports(code)\n    for s in import_suggestions:\n        diagnostics.append({\"type\": \"MissingImport\", \"message\": s[\"issue\"], \"suggestion\": s[\"suggestion\"]})\n\n    # Build a simple fix text\n    fix_lines = []\n    if diagnostics:\n        fix_lines.append(\"# Diagnostics found:\")\n        for d in diagnostics:\n            if d.get(\"suggestion\"):\n                fix_lines.append(f\"# - {d['type']}: {d['message']} -> try: {d['suggestion']}\")\n            else:\n                fix_lines.append(f\"# - {d['type']}: {d['message']}\")\n        # Prepend suggested imports if any\n        suggested_imports = [s[\"suggestion\"] for s in import_suggestions]\n        if suggested_imports:\n            fix_lines.append(\"\\n# Suggested imports:\")\n            for imp in suggested_imports:\n                fix_lines.append(imp)\n    else:\n        fix_lines.append(\"# No static issues detected. Consider runtime checks.\")\n\n    fix_text = \"\\n\".join(fix_lines)\n    # Confidence is low-to-medium because we only do static checks\n    return {\"diagnostics\": diagnostics, \"fix\": fix_text, \"confidence\": 0.7}\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-26T08:55:27.810Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile /kaggle/working/agentsmentor/backend/agents/model_agent.py\n# backend/agents/model_agent.py\nfrom pathlib import Path\n\ndef suggest_model(dataset_id: str, dataset_path: Path):\n    \"\"\"\n    Simple heuristic model suggestion for MVP.\n    Returns dictionary with recommended model and sample code cells.\n    \"\"\"\n    dataset_path = Path(dataset_path)\n    if not dataset_path.exists():\n        raise FileNotFoundError(f\"Dataset not found: {dataset_path}\")\n\n    # Heuristic: tabular -> RandomForest baseline\n    suggestion = {\n        \"recommended_model\": \"RandomForestClassifier\",\n        \"reason\": \"Good baseline for tabular problems (robust and easy).\",\n        \"preprocessing\": [\"fill missing numeric with median\", \"one-hot encode categorical\"],\n        \"sample_code_cells\": [\n            \"import pandas as pd\",\n            \"from sklearn.model_selection import train_test_split\",\n            \"from sklearn.ensemble import RandomForestClassifier\",\n            \"df = pd.read_csv('samples/{}')\".format(dataset_path.name),\n            \"# TODO: add preprocessing here\",\n            \"X = df.drop(columns=['target'], errors='ignore')\",\n            \"y = df.get('target')\",\n            \"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\",\n            \"model = RandomForestClassifier(n_estimators=100, random_state=42)\",\n            \"model.fit(X_train, y_train)\",\n            \"print('Done')\"\n        ]\n    }\n    return suggestion\n\ndef generate_notebook(dataset_id: str, dataset_path: Path):\n    \"\"\"\n    Generates a simple .py \"notebook-like\" script and saves into artifacts/notebooks/.\n    Returns the saved path as a string.\n    \"\"\"\n    dataset_path = Path(dataset_path)\n    artifacts_dir = Path(\"/kaggle/working/agentsmentor/artifacts/notebooks\")\n    artifacts_dir.mkdir(parents=True, exist_ok=True)\n\n    fname = f\"{dataset_id}_baseline.py\"\n    out_path = artifacts_dir / fname\n\n    content_lines = [\n        \"# AgentsMentor generated baseline script (MVP)\",\n        \"import pandas as pd\",\n        \"from sklearn.model_selection import train_test_split\",\n        \"from sklearn.ensemble import RandomForestClassifier\",\n        \"\",\n        f\"df = pd.read_csv('samples/{dataset_path.name}')\",\n        \"print('Loaded:', df.shape)\",\n        \"\",\n        \"# Simple preprocessing (example)\",\n        \"df = df.copy()\",\n        \"for c in df.select_dtypes(include='number').columns:\",\n        \"    df[c] = df[c].fillna(df[c].median())\",\n        \"\",\n        \"# Prepare X/y (replace 'target' with your target column name)\",\n        \"if 'target' in df.columns:\",\n        \"    X = df.drop(columns=['target'])\",\n        \"    y = df['target']\",\n        \"else:\",\n        \"    X = df.drop(columns=[df.columns[-1]])\",\n        \"    y = df[df.columns[-1]]\",\n        \"\",\n        \"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\",\n        \"model = RandomForestClassifier(n_estimators=100, random_state=42)\",\n        \"model.fit(X_train, y_train)\",\n        \"print('Training done. Sample score:', model.score(X_val, y_val))\",\n        \"\",\n        \"# Save example submission.csv (modify as needed)\",\n        \"preds = model.predict(X_val)\",\n        \"import pandas as _pd\",\n        \"_pd.DataFrame({'pred': preds}).to_csv('/kaggle/working/agentsmentor/artifacts/notebooks/prediction_sample.csv', index=False)\",\n        \"\"\n    ]\n    out_path.write_text(\"\\n\".join(content_lines), encoding=\"utf-8\")\n    return str(out_path)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-26T08:55:27.810Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%bash\nls -l /kaggle/working/agentsmentor/backend/agents\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-26T08:55:27.810Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%bash\npip install --quiet streamlit pandas scikit-learn matplotlib\npython -c \"import streamlit, pandas, sklearn, matplotlib; print('Packages OK')\"\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-26T08:55:27.810Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%bash\ncat > /kaggle/working/agentsmentor/samples/sample_titanic.csv <<'CSV'\nPassengerId,Survived,Pclass,Name,Sex,Age,SibSp,Parch,Ticket,Fare,Cabin,Embarked\n1,0,3,\"Braund, Mr. Owen Harris\",male,22,1,0,A/5 21171,7.25,,S\n2,1,1,\"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\",female,38,1,0,PC 17599,71.2833,C85,C\n3,1,3,\"Heikkinen, Miss. Laina\",female,26,0,0,STON/O2. 3101282,7.925,,S\nCSV\n\nls -l /kaggle/working/agentsmentor/samples\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-26T08:55:27.811Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%bash\n# Run Streamlit app for AgentsMentor on port 6006 (Kaggle shows a Public URL)\nstreamlit run /kaggle/working/agentsmentor/backend/app.py --server.port 6006 --server.headless true\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-26T08:55:27.811Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# example buggy code\nfrom sklearn.ensemble import RandomForestClassifier\nmodel = RandomForestClassifier()\nmodel.fit(X_train, y_train)  # but X_train not defined\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-26T08:55:27.812Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%bash\nls -l /kaggle/working/agentsmentor/backend/agents\npython -c \"import sys; print(sys.path)\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T08:59:03.626613Z","iopub.execute_input":"2025-11-26T08:59:03.626850Z","iopub.status.idle":"2025-11-26T08:59:03.729208Z","shell.execute_reply.started":"2025-11-26T08:59:03.626814Z","shell.execute_reply":"2025-11-26T08:59:03.728469Z"}},"outputs":[{"name":"stdout","text":"['', '/kaggle/lib/kagglegym', '/kaggle/lib', '/usr/lib/python311.zip', '/usr/lib/python3.11', '/usr/lib/python3.11/lib-dynload', '/usr/local/lib/python3.11/dist-packages', '/usr/lib/python3/dist-packages']\n","output_type":"stream"},{"name":"stderr","text":"ls: cannot access '/kaggle/working/agentsmentor/backend/agents': No such file or directory\n","output_type":"stream"}],"execution_count":1}]}